Dear Fangliang Zhao,

The reviews of your paper  #28 titled "COPS: A coroutine-based priority 
scheduling framework perceived by the operating system" which was 
submitted to the 21st ACM International Conference on Computing 
Frontiers 2024 (CFâ€™24), have been completed.  We regret to inform you 
that the paper is not accepted for publication at the conference. We 
understand this is a disappointing outcome and hope that the feedback 
provided by the reviewers will be helpful in further improving the 
manuscript.

Finally, we kindly invite you to participate in the conference 2024 
organized in Ischia, May 7-9, 2024 (see 
https://www.computingfrontiers.org/2024/orga.html).

 Thank you very much for your participation and contribution.

Kind regards,
Sarah Azimi and Henry Tufo
ACM Computing Frontiers Program Chairs
**********************************************************************
Submission # 28:
Review #28A
===========================================================================

Overall merit
-------------
2. Weak reject

Reviewer expertise
------------------
3. Knowledgeable

Paper summary
-------------
Muli-tasking and multi-threaded operating systems are wasteful.   Applications and OS tasks get interrupted and context switched at the wrong times.   Coroutines with futures and yield can avoid this waste.     Exploiting the Rust language support for coroutines make it possible to use coroutines within the OS itself.   The paper has built and testing such a prototype.

Comments for authors
--------------------
The writing was fine until section 3 please continue this in the rest of the sections.

It is not clear from the writing what is being currently done by the Rust runtime system and what is being proposed in this paper.

Coroutines have been around for a long time and went out of favor for several reasons. It is important to understand why coroutines failed and what is different now.   Huge address space and larger memory is one reason. The early days of smart cell phones also explored coroutines in the OS to reduce memory but more memory, program isolation, and SLAs went back to multitasking.  Again, I would like to know what is different now.
Programmers will still have trouble putting yields in the right places

I had to learn about traits, futures, etc in Rust as the paper does not do an adequate job of explaining.    

There are many recent efforts to handle interrupts in a smarter way, so there are fewer context switches between tasks.    That work  has many of the benefits of OS coroutines.

The paper would be much better if it first showed when multi-threading is wasteful and by how much.   Then it should show how, in theory co-routines can avoid this waste.   WIth that established, the paper can then show that Rust can mostly support this but with a few problems.   Finally, the paper should show how this can be fixed.

Unfortunately, given the current state of the paper, it is too hard to understand the real contribution of the work.


* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *


Review #28B
===========================================================================

Overall merit
-------------
3. Weak accept

Reviewer expertise
------------------
3. Knowledgeable

Paper summary
-------------
In this paper, the authors propose COPS, a framework that introduces coroutines in both user-space and kernel-space to reduce context-switching overhead and marshal shared resources access. COPS is built on top of Rust's stackless coroutines.

COPS introduces two Executor components, one in user-space and one in the kernel, that are used to schedule coroutines. Each Executor is capable of queueing coroutines and maintain priorities for them. COPS coordinates between user and kernel Executors and between different user Executors to do global scheduling of the coroutines according to their priorities. Explicit annotation is required to create the coroutines, either at the system call level or at the application level.

The proposed work is evaluated on an FPGA which emulates a quad-core RISC-V and runs a Rust prototype OS (rCore) through a web server application. It is shown that as the number of connections increases, the COPS approach offers lower latency and higher throughput.

Comments for authors
--------------------
Coroutines have been proven useful for handling multiple asynchronous operations, e.g., during I/O, but they are typically in user-space. This paper poses an interesting question: what if we replace threads with coroutines that are scheduled across user and kernel-space.

The motivation for this work and the proposed solution are described succinctly. The design of the system is well explained and the addition of the state machines guide the reader through the core behavior of the system. There are aspects of the design where the description could be expanded, for example how is the Executor locking implemented, what are its characteristics, etc.

However, the experimental section does not provide adequate proof that this is a viable approach. From the results in Figure 5, the benefit of using coroutines everywhere is not obvious, as the difference between KTUC (more traditional webserver implementations) and KCUC is small, as the benchmark ignores the cost of creating threads and coroutines. This means could potentially be faster than KCUC under realistic scenarios where most clients are not connected for long periods of time.

Typically, stackless coroutines require heap space to save their stack. Since there is no mention of heap allocation elision, we'll assume that they always allocate. This poses issues for syscalls, as any operation may allocate to create the coroutine that handles it. There could be serious implications in a real system regarding performance and correctness (e.g., which operations need to be blocking to avoid infinite coroutine creations).

Typos:
- 133: "lower resources requirement" -> "lower resources requirements"
- 136: "Coroutine" -> "Coroutines"
- 292: "However, Using" -> "However, using"